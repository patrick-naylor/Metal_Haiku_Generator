{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, SimpleRNN, LSTM, GRU, Conv1D, Embedding, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pronouncing\n",
    "import markovify\n",
    "import textstat\n",
    "import math\n",
    "\n",
    "import re\n",
    "import syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub(r'[^a-zA-Z]', '', lyric_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_path = '/Users/patricknaylor/Desktop/Metal/Data/lyrics_1.txt'\n",
    "\n",
    "with open(lyric_path, 'r') as file:\n",
    "    song = (file.read())\n",
    "    lyrics = song.replace('\\ufeff', '').split(\"\\n\")\n",
    "\n",
    "\n",
    "for line in lyrics:\n",
    "    line = re.sub(r'[^a-zA-Z]', '', line)\n",
    "    line = re.sub(r'x2', '', line)\n",
    "\n",
    "#print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = markovify.NewlineText(str(\"\\n\".join(lyrics)), well_formed=False, state_size=3)\n",
    "sentence = markov_model.make_sentence(tries=100)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = lyrics\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "\n",
    "V = len(tokenizer.word_index)+1\n",
    "seq = pad_sequences(tokenizer.texts_to_sequences(sequences), maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = seq[:, :-1], tf.keras.utils.to_categorical(seq[:, -1], num_classes=V)\n",
    "\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 512\n",
    "\n",
    "#Simple RNN\n",
    "T = train_X.shape[1]\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V, D)(i)\n",
    "x = Dropout(0.2)(x)\n",
    "x = SimpleRNN(150)(x)\n",
    "x = Dense(V, activation=\"softmax\")(x)\n",
    "rnn_model = Model(i, x)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "rnn_model.compile(optimizer=adam, metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau , EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "es = EarlyStopping(monitor=\"loss\", mode=\"min\", verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_r = rnn_model.fit(train_X, train_y, epochs=100,callbacks=[learning_rate_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_readability(input_bars):\n",
    "  avg_readability = 0\n",
    "  for bar in input_bars:\n",
    "    avg_readability += textstat.automated_readability_index(bar)\n",
    "  return avg_readability / len(input_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rhyme_density(bars):\n",
    "  total_syllables = 0\n",
    "  rhymed_syllables = 0\n",
    "  for bar in bars:\n",
    "    for word in bar.split():\n",
    "      p = pronouncing.phones_for_word(word)\n",
    "      if len(p) == 0:\n",
    "        break\n",
    "      syllables = pronouncing.syllable_count(p[0])\n",
    "      total_syllables += syllables\n",
    "      has_rhyme = False\n",
    "      for rhyme in pronouncing.rhymes(word):\n",
    "        if has_rhyme:\n",
    "          break\n",
    "        for idx, r_bar in enumerate(bars):\n",
    "          if idx > 4:\n",
    "            break\n",
    "          if rhyme in r_bar:\n",
    "            rhymed_syllables += syllables\n",
    "            has_rhyme = True\n",
    "            break\n",
    "  return rhymed_syllables/total_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar(seed_phrase, model, length_of_bar):\n",
    "  seed_words = ' '.join(seed_phrase.split(' ')[-2:])\n",
    "  syl = 0 + syllables.estimate(seed_words)\n",
    "  while syl < length_of_bar:\n",
    "    seed_tokens = pad_sequences(tokenizer.texts_to_sequences([seed_phrase]), maxlen=29)\n",
    "    output_p = model.predict(seed_tokens)\n",
    "    output_word = np.argmax(output_p, axis=1)[0]-1\n",
    "    syl += syllables.estimate(str(list(tokenizer.word_index.items())[output_word][0]))\n",
    "    seed_phrase += \" \" + str(list(tokenizer.word_index.items())[output_word][0])\n",
    "  return seed_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bar(input_bar, artists_bars, artists_avg_readability, artists_avg_rhyme_idx):\n",
    "  gen_readability = textstat.automated_readability_index(input_bar)\n",
    "  gen_rhyme_idx = calc_rhyme_density(input_bar)\n",
    "  comp_bars = compare_bars(input_bar, artists_bars)\n",
    "\n",
    "  # Scores based off readability, rhyme index, and originality. The lower the score the better.\n",
    "  bar_score = (artists_avg_readability - gen_readability) + (artists_avg_rhyme_idx - gen_rhyme_idx) + comp_bars\n",
    "  return bar_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bars(input_bar, artists_bars):\n",
    "  '''\n",
    "    input_bars are the fire bars our AI generates\n",
    "    artists_bars are the original bars for the artist\n",
    "\n",
    "    The lower the score the better! We want unique bars\n",
    "  '''\n",
    "  # Converts sentences to matrix of token counts\n",
    "  avg_dist = 0\n",
    "  total_counted = 0\n",
    "  for bar in artists_bars:\n",
    "    v = CountVectorizer()\n",
    "    # Vectorize the sentences\n",
    "    word_vector = v.fit_transform([input_bar, bar])\n",
    "    # Compute the cosine distance between the sentence vectors\n",
    "    cos_dist = 1-pdist(word_vector.toarray(), 'cosine')[0]\n",
    "    if not math.isnan(cos_dist):\n",
    "      avg_dist += 1-pdist(word_vector.toarray(), 'cosine')[0]\n",
    "      total_counted += 1\n",
    "  return avg_dist/total_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song( model, intro_bar, artists_bars, length_of_bar, length_of_song=20, min_score_threshold=-0.2, max_score_threshold=0.2, tries=5):\n",
    "  artists_avg_readability = calc_readability(artists_bars)\n",
    "  artists_avg_rhyme_idx = calc_rhyme_density(artists_bars)\n",
    "  fire_song = [intro_bar + \" \"]\n",
    "  bar_lengths = [7, 5]\n",
    "  cur_tries = 0\n",
    "  candidate_bars = []\n",
    "\n",
    "  while len(fire_song) < 3:\n",
    "    try:\n",
    "        seed_sentence = markov_model.make_sentence(tries=100).split(\" \")\n",
    "        print('Seed Sentence: ', seed_sentence)\n",
    "        seed_sentence = \" \".join(fire_song[-1].split(' ')[-3:]) + \" \".join(seed_sentence[:2])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    bar = generate_bar(seed_sentence, model, bar_lengths[len(fire_song)-1])\n",
    "    print(syllables.estimate(' '.join(bar.split(' ')[2:])))\n",
    "    if (syllables.estimate(' '.join(bar.split(' ')[2:])) == bar_lengths[len(fire_song) - 1]):\n",
    "      cur_tries += 1\n",
    "      print(cur_tries)\n",
    "    #print(bar)\n",
    "    bar_score = score_bar(bar, lyrics, artists_avg_readability, artists_avg_rhyme_idx) \n",
    "    candidate_bars.append((bar_score, bar))\n",
    "\n",
    "\n",
    "    if bar_score <= max_score_threshold and bar_score >= min_score_threshold and (syllables.estimate(' '.join(bar.split(' ')[3:])) == bar_lengths[len(fire_song) - 1]):\n",
    "      fire_song.append(' '.join(bar.split(' ')[2:]) + \" \")\n",
    "      cur_tries = 0\n",
    "      print(\"Generated Bar: \", len(fire_song))\n",
    "\n",
    "    if cur_tries >= tries:\n",
    "      lowest_score = np.Infinity\n",
    "      best_bar = \"\"\n",
    "      for bar in candidate_bars:\n",
    "        if (bar[0] < lowest_score) and (syllables.estimate(' '.join(bar[1].split(' ')[2:])) == bar_lengths[len(fire_song) - 1]):\n",
    "          best_bar = bar[1]\n",
    "          candidate_bars = []\n",
    "      \n",
    "      fire_song.append(' '.join(best_bar.split(' ')[2:]) + \" \")\n",
    "      print(\"Generated Bar: \", len(fire_song))\n",
    "      cur_tries = 0\n",
    "      \n",
    "  print(\"Generated song with avg rhyme density: \", calc_rhyme_density(fire_song), \"and avg readability of: \", calc_readability(fire_song))\n",
    "  return fire_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n",
    "rnn = generate_song( rnn_model, 'Death is consuming', lyrics, length_of_bar =12 , tries=5)\n",
    "\n",
    "print(\"Song Generated with SimpleRNN:\")\n",
    "for line in rnn:\n",
    "  print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "#Clean code\n",
    "#comment\n",
    "#reformat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('RE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36173ce3d0ba65c4d5858397b29ed022201e85e6fa210e17017ccab12f085240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
